{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing and Interest Rates provider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following script gathers fixing and interest rates quotes by making API calls (FX Rates) and scraping the EMMI webpage (Interest Rates)\n",
    "\n",
    "Fixing: Daily fixing rates such as EUR/USD, EUR/NOK, etc.\n",
    "\n",
    "Interest rates:\n",
    "- EURIBOR: 1 week, 1 month, 3 months, 6 months, 12 months.\n",
    "- EONIA: ON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import csv\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "API_KEY = \"123456789\" # Alpha Vantage personal key\n",
    "API_URL = \"https://www.alphavantage.co/query?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main variables\n",
    "local = \"../data/Historical_Rates.csv\"\n",
    "saveto = f\"../data/Rates_to_upload_{int(time.time())}.csv\"\n",
    "\n",
    "# Data to look up in the webpage and API\n",
    "rates_to_look_up = [\"EURIBOR\", \"USD\", \"NOK\", \"GBP\", \"JPY\", \"CHF\", \"AUD\", \"EONIA\"]\n",
    "years = [\"2020\", \"2019\"]\n",
    "\n",
    "# Filter parameters\n",
    "filter_list = [\"USD\", \"GBP\", \"NOK\", \"EURIBOR\", \"EONIA\"]\n",
    "from_date = \"01/01/2020\"\n",
    "to_date = \"15/05/2020\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_date(date_str):\n",
    "    \"\"\"\n",
    "    Takes a date like string such as 2020-05-11 and returns 11/05/2020.\n",
    "    :param date_str: date like string to convert.\n",
    "    \"\"\"\n",
    "    date_list = date_str.split(\"-\")\n",
    "    nice_date = \"/\".join(date_list[::-1])\n",
    "    return nice_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting fixing from Alpha Vantage API\n",
    "def get_single_fixing(from_cur, to_cur, api_url=API_URL, key=API_KEY):\n",
    "    \"\"\"\n",
    "    Returns a df with the last 100 quotes of a given pair (from_cur: base currency, to_cur: quote currency).\n",
    "    :param from_cur: Base currency.\n",
    "    :param to_cur: Quote currency.\n",
    "    :param api_url: API URL.\n",
    "    :param key: API key.\n",
    "    \"\"\"\n",
    "    \n",
    "    params = {\"function\": \"FX_DAILY\", \"from_symbol\": from_cur.upper(), \"to_symbol\": to_cur.upper(),\n",
    "              \"apikey\": key, \"datatype\": \"json\"}\n",
    "    r = requests.get(api_url, params=params)\n",
    "    \n",
    "    # Creates a df if the connection was successful\n",
    "    if r.status_code == 200:\n",
    "        r_json = r.json() # turns the response object into a JSON dictionary-like object\n",
    "\n",
    "        too_quick = \"standard API call frequency is 5 calls per minute and 500 calls per day\"\n",
    "\n",
    "        try:\n",
    "            fix_df = pd.DataFrame(r_json[\"Time Series FX (Daily)\"]).T # Creates a df\n",
    "            fix_df.drop(columns=fix_df.columns[0:3], inplace=True) # Drops Open, High and Low columns\n",
    "            fix_df.reset_index(inplace=True, drop=False) # Sets index as integers and places dates into a column\n",
    "            fix_df[\"Currency\"] = to_cur # Creates a new column with the quote currency (to_cur)\n",
    "            fix_df.columns = [\"Date\", \"Value\", \"Rate\"] # Renames all columns\n",
    "            fix_df[\"Date\"] = fix_df[\"Date\"].apply(lambda x : format_date(x)) # 2020-05-11 -> 11/05/2020\n",
    "        \n",
    "              # Use this to make a nice plot :)\n",
    "#             fix_df.reset_index(drop=False, inplace=True)\n",
    "#             fix_df.columns = [\"Date\", \"Open\", \"High\", \"Low\", \"Close\"] # Renames all columns\n",
    "#             fix_df[\"Date\"] = fix_df[\"Date\"].apply(lambda x : format_date(x)) # 2020-05-11 -> 11/05/2020\n",
    "#             fix_df[\"Currency Pair\"] = f\"{from_cur}/{to_cur}\"\n",
    "\n",
    "            return fix_df\n",
    "\n",
    "        except LookupError:\n",
    "            print(\"Alpha Vantage free account only supports 5 calls per minute and 500 calls per day\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Error retrieving fixing data from the API\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathers Interest Rates from the EMMI webpage. It's a csv file.\n",
    "def get_single_interest_rate(rate, year):\n",
    "    \"\"\"\n",
    "    Returns a raw data frame with three columns; Rate, Value (close price), and Date.\n",
    "    :param rate: Interest rate to request; EURIBOR or EONIA.\n",
    "    :param year: Year to request being 1999 the oldest available year.\n",
    "    \"\"\"\n",
    "    \n",
    "    if rate.upper() == \"EURIBOR\":\n",
    "    \n",
    "        url = (f\"https://www.emmi-benchmarks.eu/assets/components/rateisblue/\"\n",
    "               f\"file_processing/publication/processed/hist_{rate.upper()}_{year}.csv\")\n",
    "\n",
    "        r = requests.get(url)\n",
    "\n",
    "        if r.status_code == 200:\n",
    "            # Formatting raw csv data into pandas dataframe\n",
    "            raw_csv =  r.text.split(\"\\n\") # splits by /n\n",
    "            raw_list = [row.lstrip(\",\").rstrip(\",\").split(\",\") for row in raw_csv] # splits the csv file into rows\n",
    "            raw_list[0].insert(0, \"Rate\") # adds header, should be the same in the melt function below.\n",
    "            raw_list.pop() # deletes last empty row\n",
    "            raw_df = pd.DataFrame(raw_list[1:], columns=raw_list[0]) # creates df\n",
    "            raw_df = pd.melt(raw_df, id_vars=[\"Rate\"], value_vars=raw_df.columns[1:], \n",
    "                             var_name=\"Date\", value_name=\"Value\") # Turns columns (dates) into rows\n",
    "            raw_df = raw_df[[\"Date\", \"Value\", \"Rate\"]] # Rearranging columns\n",
    "\n",
    "            return raw_df\n",
    "\n",
    "        else:\n",
    "            # if status code is different from 200, returns None\n",
    "            print(f\"Error downloading {rate} data from: {url}\")\n",
    "            return None\n",
    "        \n",
    "    elif rate.upper() == \"EONIA\":\n",
    "        \n",
    "        url = (f\"https://www.emmi-benchmarks.eu/assets/components/rateisblue/\"\n",
    "               f\"file_processing/publication/processed/hist_{rate.upper()}_{year}.csv\")\n",
    "\n",
    "        r = requests.get(url)\n",
    "\n",
    "        if r.status_code == 200:\n",
    "            # Formatting raw csv data into pandas dataframe\n",
    "            raw_csv =  r.text.split(\"\\n\") # splits by /n\n",
    "            raw_list = [row.lstrip(\",\").rstrip(\",\").split(\",\") for row in raw_csv] # splits the csv file into rows\n",
    "            raw_list[0].insert(0, \"Rate\") # add missing header, should be the same that in the melt function below\n",
    "            raw_list.pop() # deletes last empty row\n",
    "            raw_list.pop() # deletes volume ON (in mln euro) row\n",
    "            raw_df = pd.DataFrame(raw_list[1:], columns=raw_list[0]) # creates df\n",
    "            raw_df = pd.melt(raw_df, id_vars=[\"Rate\"], value_vars=raw_df.columns[1:], \n",
    "                             var_name=\"Date\", value_name=\"Value\") # Turns columns (dates) into rows\n",
    "            raw_df = raw_df[[\"Date\", \"Value\", \"Rate\"]] # Rearranging columns\n",
    "\n",
    "            return raw_df\n",
    "\n",
    "        else:\n",
    "            # if status code is different from 200, returns None\n",
    "            print(f\"Error downloading {rate} data from: {url}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(original_df, clean_type):\n",
    "    \"\"\"\n",
    "    Returns a 3 columns formatted dataframe.\n",
    "    :param original_df: Raw 3 columns dataframe to enhance\n",
    "    :param clean_type: \"EURIBOR\", \"EONIA\" or \"FX\"\n",
    "    \"\"\"\n",
    "    df = original_df.copy()\n",
    "    \n",
    "    df[\"Value\"] = pd.to_numeric(df[\"Value\"])\n",
    "    df[\"Rate\"] = pd.Categorical(df[\"Rate\"])\n",
    "    \n",
    "    # 1w -> EUR1W\n",
    "    if  clean_type.upper() == \"EURIBOR\":\n",
    "        df[\"Rate\"] = df[\"Rate\"].apply(lambda x: f\"EUR{x.upper()}\")\n",
    "        \n",
    "    \n",
    "    elif clean_type.upper() == \"EONIA\":\n",
    "        df[\"Rate\"] = df[\"Rate\"].apply(lambda x: f\"EONIA\")\n",
    "    \n",
    "    # Not specific formatting needed for fixing\n",
    "    elif clean_type.upper() == \"FX\":\n",
    "        pass\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_local(local_file):\n",
    "    \"\"\"\n",
    "    Creates a csv file to save historical rates. This file will be used to look up rates later on.\n",
    "    :param local_file: Historical rates csv file path.\n",
    "    \"\"\"\n",
    "    # Creates a csv file with just one row (headers) \"Date\", \"Value\" and \"Rate\"\n",
    "    with open(local_file, \"w\") as f: \n",
    "        headers = [[\"Date\", \"Value\", \"Rate\"]]\n",
    "        csv_writer = csv.writer(f)\n",
    "        for line in headers:\n",
    "            csv_writer.writerow(line)\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_local(local_file, df_to_add):\n",
    "    \"\"\"\n",
    "    Updates rates file. This is where all looked up rates will be stored.\n",
    "    :param local_file: Historical rates csv file path.\n",
    "    :param df_to_add: Dataframe. New data to add to the csv.\n",
    "    \"\"\"\n",
    "    # Checks whether the file exists. If not, it will create it. \n",
    "    if os.path.exists(local_file):\n",
    "        df = pd.read_csv(local_file)\n",
    "        \n",
    "        # Check if it has the same format, it won't concatenate otherwise \n",
    "        comparison = df.columns == df_to_add.columns\n",
    "        if comparison.all():\n",
    "            full = pd.concat([df, df_to_add])\n",
    "            full.drop_duplicates(subset=[\"Date\", \"Rate\"], keep=\"first\", inplace=True)\n",
    "            full.to_csv(local_file, index=False)\n",
    "            full.reset_index(drop=True, inplace=True)\n",
    "            print(f\"File updated: {local_file}\")\n",
    "            return full\n",
    "        else:\n",
    "            print(f\"Dataframes cannot be concatenated.\"\n",
    "                  f\"local file columns: {len(df.columns)}, df to add columns: {len(df_to_add.columns)}\")\n",
    "            return None\n",
    "        \n",
    "    else:\n",
    "        # Creates rates file and calls the same function again.\n",
    "        create_local(local_file)\n",
    "        print(f\"New file created at: {local_file}\")\n",
    "        full_df = update_local(local_file, df_to_add)\n",
    "        return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenator(list_of_df):\n",
    "    \"\"\"\n",
    "    Takes a bunch of dataframes and blends them together vertically.\n",
    "    :param list_of_df: List of dataframes.\n",
    "    \"\"\"\n",
    "    full_df = pd.concat(list_of_df)\n",
    "    sorted_df = full_df.sort_values(by=[\"Date\", \"Rate\"])\n",
    "    sorted_df.reset_index(inplace=True, drop=True)\n",
    "    return sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiple_rates(list_rates, interest_rate_years):\n",
    "    \"\"\"\n",
    "    Returns a dataframes with all requested rates\n",
    "    :param list_rates: List of requested rates, FX and interest rates alike. [\"EURIBOR\", \"USD\", \"NOK\"]\n",
    "    :param interest_rate_year: List of years, only applicable to interest rates. [\"2020\", \"2019\"]\n",
    "    \"\"\"\n",
    "    print(\"Gathering data...\")\n",
    "    df_rates_list = [] # here will be stored all requested rates\n",
    "    \n",
    "    for rate in list_rates:\n",
    "        # Runs interest rate function if rate is EURIBOR or EONIA\n",
    "        if rate.upper() == \"EURIBOR\" or rate.upper() == \"EONIA\":\n",
    "            # Loops through each requested year\n",
    "            for year in interest_rate_years:\n",
    "                print(f\"Gathering {rate}, year {year}\")\n",
    "                current_interest_rate = clean_df(get_single_interest_rate(rate, year), rate)\n",
    "                df_rates_list.append(current_interest_rate)\n",
    "        \n",
    "        # Runs fixing function if requested rate is different from EURIBOR or EONIA\n",
    "        else:\n",
    "            print(f\"Gathering {rate}\")\n",
    "            current_fixing = clean_df(get_single_fixing(\"EUR\", rate), \"FX\")\n",
    "            df_rates_list.append(current_fixing)\n",
    "    \n",
    "    bunch_of_rates = concatenator(df_rates_list)\n",
    "    print(\"Data gathered successfully!\")\n",
    "    \n",
    "    return bunch_of_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def look_up(df_path, rates_list, date_from, date_to=0):\n",
    "    \"\"\"\n",
    "    Filters historical data given a range of dates and a set of rates. Returns a df\n",
    "    \n",
    "    :param df_path: CSV file to sort through. \n",
    "    :param rates_list: Filter. Rates to show up (EUR12M, USD, GBP, etc)\n",
    "    :param date_from: Initial date. Inclusive\n",
    "    :param date_to: End date. Inclusive. This parameter will take date_from value if it's set to 0\n",
    "    \"\"\"\n",
    "    \n",
    "    # Switching day and month position\n",
    "    date_from = date_from.split(\"/\")\n",
    "    date_from = date_from[1] + \"/\" + date_from[0] + \"/\" + date_from[2]\n",
    "    \n",
    "    # If date_to is empty, it will just return one day -> date_from\n",
    "    if date_to == 0:\n",
    "        date_to = date_from\n",
    "    else:\n",
    "        # Switching day and month position\n",
    "        date_to = date_to.split(\"/\")\n",
    "        date_to = date_to[1] + \"/\" + date_to[0] + \"/\" + date_to[2]\n",
    "        \n",
    "    # Loading historical rates. csv file\n",
    "    df = pd.read_csv(df_path)\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], dayfirst=True)\n",
    "    \n",
    "    # Turning all rates into uppercase and adding all possible Euribor rates\n",
    "    rates_list = [i.upper() for i in rates_list]\n",
    "    rates_list.extend([\"EUR12M\", \"EUR9M\", \"EUR6M\", \"EUR3M\", \"EUR1M\", \"EUR1W\"]) if \"EURIBOR\" in rates_list else None\n",
    "    \n",
    "    # Filtering and sorting data\n",
    "    filtered_df = df.loc[(df.Date >= date_from) & (df.Date <= date_to) & (df.Rate.isin(rates_list))]\n",
    "    sorted_df = filtered_df.sort_values(by=[\"Date\", \"Rate\"], ascending=True, na_position=\"first\")\n",
    "    sorted_df.reset_index(drop=True, inplace=True)\n",
    "    sorted_df.loc[:, \"Date\"] = sorted_df[\"Date\"].dt.strftime(\"%d/%m/%Y\")\n",
    "    \n",
    "    # Saving df into a csv file\n",
    "    df.to_csv(saveto, index=False)\n",
    "    print(f\"Filtered data saved at: {saveto}\")\n",
    "    \n",
    "    return sorted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting rates from Alpha Vantage API and EMMI webpage\n",
    "rates_to_look_up = [\"EURIBOR\", \"USD\", \"NOK\", \"GBP\", \"JPY\", \"CHF\", \"AUD\", \"EONIA\"]\n",
    "years = [\"2020\", \"2019\"]\n",
    "\n",
    "df = get_multiple_rates(rates_to_look_up, years) # null values in 2018\n",
    "\n",
    "# Saving gathered rates into a csv file\n",
    "raw = update_local(local, df)\n",
    "\n",
    "# Filtering relevant rates. Save filtered df into a csv file.\n",
    "r_list = [\"USD\", \"GBP\", \"NOK\", \"EURIBOR\", \"EONIA\"]\n",
    "result = look_up(local, r_list, \"01/01/2020\", \"15/05/2020\")\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:labs_env]",
   "language": "python",
   "name": "conda-env-labs_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
